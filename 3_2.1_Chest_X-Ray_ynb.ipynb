{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a294a3",
   "metadata": {},
   "source": [
    "### Pneumonia Detection on Chest X-ray Images Using Deep Learning\n",
    "\n",
    "The dataset of this project is obtained from the https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "### Data set:\n",
    "The dataset is organized into 3 folders (train, test, val) and contains subfolders of each image category (Pneumonia / Normal). There are 5,863 X-Ray images (JPEG) and 2 categories(Pneumonia/Normal)\n",
    "\n",
    "Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care.\n",
    "\n",
    "For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1492f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten, Conv2D,MaxPooling2D,BatchNormalization,Input\n",
    "from tensorflow.keras.regularizers import L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2520a4f",
   "metadata": {},
   "source": [
    "## Architecture of Model:\n",
    "### input:\n",
    "- input: (224,224,1)\n",
    "\n",
    "### convolution Layers:\n",
    "- conv1: 32 size (7,7) # kernel size should be always odd numbers only \n",
    "- Batch normalization\n",
    "- pool1: (3,3)\n",
    "- dropout layer-1: 20% # to address overfitiing \n",
    "\n",
    "- conv2: 64 size (7,7) # kernel size should be always odd numbers only \n",
    "- Batch normalization\n",
    "- pool2: (3,3)\n",
    "- dropout layer-2: 20% # to address overfitiing \n",
    "\n",
    "- conv3: 128 size (7,7) # kernel size should be always odd numbers only \n",
    "- Batch normalization\n",
    "- pool3: (3,3)\n",
    "- dropout layer-3: 20%  # to address overfitiing \n",
    "\n",
    "\n",
    "### Flatten layer:\n",
    "- Flatten: \n",
    "\n",
    "### Fully connecte Layer:\n",
    "- Dense1: with 1024 nodes\n",
    "- Batch normalization\n",
    "- dropout layer: 25% # to address overfitiing \n",
    "\n",
    "- Dense2: with 512 nodes\n",
    "- Batch normalization \n",
    "- dropout layer: 25% # to address overfitiing \n",
    "\n",
    "- Dense3: with 256 nodes\n",
    "- Batch normalization \n",
    "- dropout layer: 25% # to address overfitiing\n",
    "\n",
    "- Dense4: with 64 nodes\n",
    "- Batch normalization \n",
    "- dropout layer: 25% # to address overfitiing\n",
    "\n",
    "- Dense(**output**):with 2 nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b565085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input laye\n",
    "x=Input(shape=(224,224,1)) \n",
    "\n",
    "# conv1\n",
    "conv1=Conv2D(filters=32,kernel_size=(7,7),activation='relu',padding='same',name='conv1')(x)\n",
    "bn_conv1=BatchNormalization(name='bn_conv1')(conv1)\n",
    "pool1=MaxPooling2D(pool_size=(3,3),name='pool1')(bn_conv1)\n",
    "dr_conv1=Dropout(rate=0.2)(pool1)\n",
    "\n",
    "# conv2\n",
    "conv2=Conv2D(filters=64,kernel_size=(7,7),activation='relu',padding='same',name='conv2')(dr_conv1)\n",
    "bn_conv2=BatchNormalization(name='bn_conv2')(conv2)\n",
    "pool2=MaxPooling2D(pool_size=(3,3),name='pool2')(bn_conv2)\n",
    "dr_conv2=Dropout(rate=0.2)(pool2)\n",
    "\n",
    "# conv3\n",
    "conv3=Conv2D(filters=128,kernel_size=(7,7),activation='relu',padding='same',name='conv3')(dr_conv2)\n",
    "bn_conv3=BatchNormalization(name='bn_conv3')(conv3)\n",
    "pool3=MaxPooling2D(pool_size=(3,3),name='pool3')(bn_conv3)\n",
    "dr_conv3=Dropout(rate=0.2)(pool3)\n",
    "\n",
    "# flatten layer\n",
    "flatten=Flatten()(dr_conv3)\n",
    "\n",
    "# dense1\n",
    "dense1=Dense(1024,activation='relu',kernel_regularizer=L1(l1=0.01),name='dense1')(flatten)\n",
    "bn1=BatchNormalization(name='bn1_d1')(dense1)\n",
    "dr1=Dropout(0.25,name='dr1_d1')(bn1) \n",
    "\n",
    "# dense2\n",
    "dense2=Dense(512,activation='relu',kernel_regularizer=L1(l1=0.01),name='dense2')(dr1)\n",
    "bn2=BatchNormalization(name='bn2_d2')(dense2)\n",
    "dr2=Dropout(0.25,name='dr2_d2')(bn2)\n",
    "\n",
    "# dense3\n",
    "dense3=Dense(256,activation='relu',kernel_regularizer=L1(l1=0.01),name='dense3')(dr2)\n",
    "bn3=BatchNormalization(name='bn3_d3')(dense3)\n",
    "dr3=Dropout(0.25,name='dr3_d3')(bn3)\n",
    "\n",
    "# dense4\n",
    "dense4=Dense(64,activation='relu',kernel_regularizer=L1(l1=0.01),name='dense4')(dr3)\n",
    "bn4=BatchNormalization(name='bn4_d4')(dense4)\n",
    "dr4=Dropout(0.25,name='dr4_d4')(bn4)\n",
    "\n",
    "# output\n",
    "output=Dense(2,activation='softmax',name='output')(dr4)\n",
    "\n",
    "# model\n",
    "model_xray=Model(inputs=x,outputs=output) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e46b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 224, 224, 32)      1600      \n",
      "                                                                 \n",
      " bn_conv1 (BatchNormalizati  (None, 224, 224, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 74, 74, 32)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 74, 74, 32)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 74, 74, 64)        100416    \n",
      "                                                                 \n",
      " bn_conv2 (BatchNormalizati  (None, 74, 74, 64)        256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 24, 24, 128)       401536    \n",
      "                                                                 \n",
      " bn_conv3 (BatchNormalizati  (None, 24, 24, 128)       512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 1024)              8389632   \n",
      "                                                                 \n",
      " bn1_d1 (BatchNormalization  (None, 1024)              4096      \n",
      " )                                                               \n",
      "                                                                 \n",
      " dr1_d1 (Dropout)            (None, 1024)              0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 512)               524800    \n",
      "                                                                 \n",
      " bn2_d2 (BatchNormalization  (None, 512)               2048      \n",
      " )                                                               \n",
      "                                                                 \n",
      " dr2_d2 (Dropout)            (None, 512)               0         \n",
      "                                                                 \n",
      " dense3 (Dense)              (None, 256)               131328    \n",
      "                                                                 \n",
      " bn3_d3 (BatchNormalization  (None, 256)               1024      \n",
      " )                                                               \n",
      "                                                                 \n",
      " dr3_d3 (Dropout)            (None, 256)               0         \n",
      "                                                                 \n",
      " dense4 (Dense)              (None, 64)                16448     \n",
      "                                                                 \n",
      " bn4_d4 (BatchNormalization  (None, 64)                256       \n",
      " )                                                               \n",
      "                                                                 \n",
      " dr4_d4 (Dropout)            (None, 64)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9574210 (36.52 MB)\n",
      "Trainable params: 9570050 (36.51 MB)\n",
      "Non-trainable params: 4160 (16.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_xray.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0456ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xray.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d956ea",
   "metadata": {},
   "source": [
    "### Creating data generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4b02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraies for image Augmentation\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44dd9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "# Generate batches of tensor image data with real-time data augmentation.\n",
    "train_data_gen=ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    #rescale=1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "validation_data_gen=ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    #rescale=1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d23d3",
   "metadata": {},
   "source": [
    "### Loading the data into DataGenerator \n",
    "The method ***\"flow_from_directory\"*** loads the data recursively by going to the directory by directory if our main directory is in a hierarchical fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4eaffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "width=224\n",
    "height=224\n",
    "batch_size=32\n",
    "train_dir=r'F:/YNaiduBabu/DL_by_LalithSachan/Download_Data/chest_xray/train'\n",
    "test_dir=r'F:/YNaiduBabu/DL_by_LalithSachan/Download_Data/chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fdda78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generating data and passing as batches with specific trget size\n",
    "train_generator=train_data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(height,width),\n",
    "    color_mode='grayscale',# it genrates image of (height, width,3) because colour image: 'rgb'\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator=validation_data_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(height,width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0eaa387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.9448173005219984, 1: 0.6730322580645162}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "cw = class_weight.compute_class_weight(class_weight='balanced', \n",
    "                                       classes=np.unique(train_generator.classes),\n",
    "                                       y=train_generator.classes)\n",
    "\n",
    "cw_dict = dict(enumerate(cw))\n",
    "cw_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f3c9e",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed2a3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f93b85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS =50\n",
    "STEPS_PER_EPOCH= train_generator.n//train_generator.batch_size\n",
    "VALIDATION_STEPS=validation_generator.n//train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d1423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoping=EarlyStopping(monitor='val_loss',\n",
    "              patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7053bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new folder if it doesnot exists\n",
    "outputFolder='./chest_xray_model_from_scratch_output'\n",
    "if not os.path.exists(outputFolder):\n",
    "  os.makedirs(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9875d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint: Callback to save the Keras model or model weights at some frequency.\n",
    "file_path=outputFolder+'/weights-{epoch:02d}-{loss:.4f}-{accuracy:.4f}-{val_accuracy:.4f}.h5'\n",
    "checkpoint=ModelCheckpoint(filepath=file_path,\n",
    "                           save_weights_only=True,\n",
    "                           monitor='val_accurary',\n",
    "                           mode='max',\n",
    "                           save_best_only=False,\n",
    "                           #save_freq=41\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b36ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "163/163 [==============================] - 136s 835ms/step - loss: 53.2489 - accuracy: 0.7170 - val_loss: 48.4602 - val_accuracy: 0.6250\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 136s 831ms/step - loss: 50.4602 - accuracy: 0.7615 - val_loss: 52.0528 - val_accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 136s 830ms/step - loss: 49.4066 - accuracy: 0.7926 - val_loss: 47.9379 - val_accuracy: 0.5921\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 136s 835ms/step - loss: 49.2137 - accuracy: 0.8131 - val_loss: 49.5655 - val_accuracy: 0.6201\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 150s 919ms/step - loss: 48.7328 - accuracy: 0.8252 - val_loss: 48.7016 - val_accuracy: 0.7253\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 168s 1s/step - loss: 48.4420 - accuracy: 0.8315 - val_loss: 48.0993 - val_accuracy: 0.6349\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 140s 858ms/step - loss: 48.6085 - accuracy: 0.8459 - val_loss: 49.1215 - val_accuracy: 0.5872\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 48.1843 - accuracy: 0.8604 - val_loss: 49.4649 - val_accuracy: 0.7336\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 135s 827ms/step - loss: 48.0380 - accuracy: 0.8409 - val_loss: 48.0770 - val_accuracy: 0.7418\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 136s 835ms/step - loss: 47.9391 - accuracy: 0.8622 - val_loss: 48.3281 - val_accuracy: 0.5082\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 136s 832ms/step - loss: 47.9267 - accuracy: 0.8675 - val_loss: 50.3968 - val_accuracy: 0.6118\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 47.8217 - accuracy: 0.8589 - val_loss: 47.3487 - val_accuracy: 0.5855\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 136s 831ms/step - loss: 47.4233 - accuracy: 0.8765 - val_loss: 48.7475 - val_accuracy: 0.6266\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 136s 834ms/step - loss: 47.4523 - accuracy: 0.8685 - val_loss: 47.0996 - val_accuracy: 0.6234\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 135s 829ms/step - loss: 47.1887 - accuracy: 0.8777 - val_loss: 48.7075 - val_accuracy: 0.7714\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 136s 832ms/step - loss: 47.2858 - accuracy: 0.8804 - val_loss: 47.1184 - val_accuracy: 0.6299\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 136s 830ms/step - loss: 47.0253 - accuracy: 0.8744 - val_loss: 47.5345 - val_accuracy: 0.7072\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 135s 826ms/step - loss: 47.0605 - accuracy: 0.8852 - val_loss: 48.5917 - val_accuracy: 0.3882\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 136s 831ms/step - loss: 46.9694 - accuracy: 0.8907 - val_loss: 46.8880 - val_accuracy: 0.6102\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 46.8530 - accuracy: 0.8813 - val_loss: 48.7846 - val_accuracy: 0.4260\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 135s 828ms/step - loss: 46.8553 - accuracy: 0.8863 - val_loss: 48.6223 - val_accuracy: 0.7730\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 46.8545 - accuracy: 0.8859 - val_loss: 47.5266 - val_accuracy: 0.6201\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 136s 834ms/step - loss: 46.7531 - accuracy: 0.8886 - val_loss: 46.0527 - val_accuracy: 0.8076\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 136s 830ms/step - loss: 46.7998 - accuracy: 0.9007 - val_loss: 47.3834 - val_accuracy: 0.6234\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 46.6718 - accuracy: 0.8944 - val_loss: 48.2555 - val_accuracy: 0.4786\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 136s 836ms/step - loss: 46.6331 - accuracy: 0.8915 - val_loss: 47.0104 - val_accuracy: 0.7763\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 46.6577 - accuracy: 0.8938 - val_loss: 47.7380 - val_accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 135s 827ms/step - loss: 46.5577 - accuracy: 0.9047 - val_loss: 49.0922 - val_accuracy: 0.6562\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 46.5262 - accuracy: 0.9015 - val_loss: 46.7863 - val_accuracy: 0.6414\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 135s 828ms/step - loss: 46.5644 - accuracy: 0.8961 - val_loss: 46.4794 - val_accuracy: 0.7697\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 136s 832ms/step - loss: 46.5434 - accuracy: 0.8995 - val_loss: 46.4554 - val_accuracy: 0.8536\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 135s 830ms/step - loss: 46.4414 - accuracy: 0.9068 - val_loss: 47.0372 - val_accuracy: 0.6217\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 136s 835ms/step - loss: 46.3605 - accuracy: 0.9145 - val_loss: 47.1421 - val_accuracy: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e2fe669450>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xray.fit(\n",
    "    train_generator,\n",
    "    #class_weight=cw_dict,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=VALIDATION_STEPS, \n",
    "    callbacks=[early_stoping,checkpoint],\n",
    "    verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_json = model_fn.to_json()\n",
    "\n",
    "# saving the model architecture\n",
    "with open(\"F:/YNaiduBabu/DL_by_LalithSachan/Download_Data/chest_xray/model_xray_json_v0.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d32ab5",
   "metadata": {},
   "source": [
    "till now we got best results **At Epoch 31** : with **training accuray: 89.95% and validation accuracy: 85.36%.** \n",
    "\n",
    "we saved weights of the model and model architecture for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daeb174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
